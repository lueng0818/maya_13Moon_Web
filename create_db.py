import sqlite3
import pandas as pd
import os
import glob

DB_NAME = "13moon.db"
DATA_DIR = "data"

def find_file(keyword):
    if not os.path.exists(DATA_DIR): return None
    files = glob.glob(os.path.join(DATA_DIR, "*.csv"))
    for f in files:
        if keyword in os.path.basename(f): return f
    return None

def read_csv_robust(file_path, **kwargs):
    encodings = ['utf-8', 'cp950', 'big5', 'utf-8-sig', 'gbk']
    for enc in encodings:
        try: return pd.read_csv(file_path, encoding=enc, **kwargs)
        except: continue
    return None

def init_db():
    print(f"ğŸš€ é–‹å§‹å»ºç½®è³‡æ–™åº«: {DB_NAME}...")
    conn = sqlite3.connect(DB_NAME)
    
    # 1. åƒç…§è¡¨è¨­å®š (åŒ…å«é—œéµçš„ 13:28 å°ç…§è¡¨)
    # æ ¼å¼: (CSVé—œéµå­—, è³‡æ–™åº«è¡¨å, ç´¢å¼•æ¬„ä½)
    tables_config = [
        ("kin_start_year", "Kin_Start", 'å¹´ä»½'), 
        ("month_day_accum", "Month_Accum", 'æœˆä»½'), 
        ("kin_basic_info", "Kin_Basic", 'KIN'), 
        ("PSIå°è¨˜å°ç…§è¡¨", "PSI_Bank", 'æœˆæ—¥'),
        ("å¥³ç¥å°è¨˜", "Goddess_Seal", 'KIN'),
        # ğŸ‘‡ é—œéµï¼ä¸€å®šè¦æœ‰é€™ä¸€è¡Œï¼Œç¨‹å¼æ‰æœƒå»è®€æ–°çš„ CSV
        ("å°æ‡‰ç‘ªé›…ç”Ÿæ—¥", "Maya_1328_Map", "æœˆæ—¥") 
    ]

    for kw, table, idx in tables_config:
        f = find_file(kw)
        if f:
            print(f"è™•ç†æª”æ¡ˆ: {f} -> è¡¨æ ¼: {table}")
            df = read_csv_robust(f)
            if df is not None:
                # æ¸…ç†æ¬„ä½åç¨± (ç§»é™¤å‰å¾Œç©ºç™½)
                df.columns = [str(c).strip() for c in df.columns]
                
                # æ•¸å€¼æ¬„ä½è½‰å‹ (é¿å…æ•¸å­—è®Šæ–‡å­—)
                if 'PSIå°è¨˜' in df.columns:
                    df['PSIå°è¨˜'] = pd.to_numeric(df['PSIå°è¨˜'], errors='coerce').fillna(0).astype(int)
                if 'KIN' in df.columns: 
                    df['KIN'] = pd.to_numeric(df['KIN'], errors='coerce').fillna(0).astype(int)
                
                df.to_sql(table, conn, if_exists="replace", index=False)
                if idx in df.columns: 
                    conn.execute(f"CREATE INDEX IF NOT EXISTS idx_{table} ON {table} ({idx})")
        else:
            print(f"âš ï¸ æ‰¾ä¸åˆ°é—œéµå­— '{kw}' çš„ CSV æª”æ¡ˆï¼Œå°‡è·³éå»ºç«‹ {table}ï¼")

    # 2. æ ¸å¿ƒè³‡æ–™ (å“çˆ¾é‡‘æ›†ã€çŸ©é™£ã€æ˜“ç¶“...)
    for kw, table in [("å“çˆ¾é‡‘æ›†", "Kin_Data"), ("çŸ©é™£", "Matrix_Data"), ("éŠ€æ²³æ˜“ç¶“", "IChing"), ("æ˜Ÿéš›å¹´", "Star_Years")]:
        f = find_file(kw)
        if f:
            if kw == "çŸ©é™£": 
                try:
                    df = read_csv_robust(f, header=[0, 1])
                    new_cols = []
                    last_top = "Unknown"
                    for top, bottom in df.columns:
                        if "Unnamed" not in str(top): last_top = str(top).strip()
                        clean_bottom = str(bottom).replace('\n', '').strip()
                        new_cols.append(f"{last_top}_{clean_bottom}")
                    final_cols = []
                    counts = {}
                    for col in new_cols:
                        if col in counts:
                            counts[col] += 1
                            final_cols.append(f"{col}_{counts[col]}")
                        else:
                            counts[col] = 1
                            final_cols.append(col)
                    df.columns = final_cols
                except: df = None
            else: 
                df = read_csv_robust(f)
            
            if df is not None:
                if kw != "çŸ©é™£": df.columns = [str(c).strip() for c in df.columns]
                df.to_sql(table, conn, if_exists="replace", index=False)
                
    # 3. ç¢ºä¿ä½¿ç”¨è€…è¡¨æ ¼å­˜åœ¨
    conn.execute("CREATE TABLE IF NOT EXISTS Users (id INTEGER PRIMARY KEY AUTOINCREMENT, å§“å TEXT, ç”Ÿæ—¥ TEXT, KIN INTEGER, ä¸»å°è¨˜ TEXT)")
    
    conn.close()
    print("ğŸ‰ è³‡æ–™åº«å»ºç½®å®Œæˆï¼")

if __name__ == "__main__":
    init_db()
